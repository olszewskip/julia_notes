{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "using Flux: σ, softmax, logitcrossentropy, Chain, Optimise, onehotbatch, onecold\n",
    "using Flux.Data: MNIST\n",
    "using SparseArrays\n",
    "using StatsBase: sample, shuffle, mean\n",
    "#using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST.labels();\n",
    "label_pool = sort(Vector(collect(Set(labels))));\n",
    "y = onehotbatch(labels, label_pool);\n",
    "\n",
    "imgs = MNIST.images();\n",
    "# lighter_than(pixel, threshold) = pixel.val > threshold\n",
    "# function lightness_threshold(pixel_array::Array{T, 2}, threshold) where T\n",
    "#     convert.(T, lighter_than.(pixel_array, threshold))\n",
    "# end\n",
    "# imgs_blackenwhite = lightness_threshold.(imgs, 0.7);\n",
    "#X = hcat(convert.(Array{Float32, 1}, reshape.(imgs_blackenwhite, :))...);\n",
    "X = hcat(convert.(Array{Float32, 1}, reshape.(imgs, :))...);\n",
    "\n",
    "index_train = floor(Int, 0.7 * size(X, 2))\n",
    "index_val = index_train + floor(Int, 0.2 * size(X, 2))\n",
    "X_train = X[:, 1:index_train];\n",
    "y_train = y[:, 1:index_train];\n",
    "X_val = X[:, index_train+1:index_val];\n",
    "y_val = y[:, index_train+1:index_val];\n",
    "X_test = X[:, index_val+1:end];\n",
    "y_test = y[:, index_val+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct SprAffine{S,T,F}\n",
    "    W::S\n",
    "    b::T\n",
    "    σ::F\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, layer::SprAffine)\n",
    "  print(io, \"SprAffine(\", size(layer.W, 2), \", \", size(layer.W, 1))\n",
    "  print(io, \", \", round(length(layer.W.nzval) / length(layer.W), sigdigits=6))\n",
    "  layer.σ == identity || print(io, \", \", layer.σ)\n",
    "  print(io, \")\")\n",
    "end\n",
    "\n",
    "SprAffine(in::Number, out::Number, frac::AbstractFloat, σ::Function=identity) =\n",
    "    #SprAffine(spones(out, in, frac), spzeros(out), fraq, σ)\n",
    "    SprAffine(sprandn(Float32, out, in, frac), zeros(Float32, out), σ)\n",
    "\n",
    "(layer::SprAffine)(x) = layer.σ.(layer.W * x .+ layer.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(model, X, y)\n",
    "    return logitcrossentropy(model(X), y)\n",
    "end\n",
    "accuracy(model, X, y) = mean(onecold(softmax(model(X))) .== onecold(y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_model (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_model(in, hidden, out, fraction)\n",
    "    return Chain(\n",
    "            SprAffine(in, hidden, fraction),\n",
    "            SprAffine(hidden, out, fraction),\n",
    "           );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15625"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(size(X, 1), 100, size(y, 1), 0.1)\n",
    "loss(model, sparse(X[:, 1:32]), y[:, 1:32])\n",
    "accuracy(model, sparse(X[:, 1:32]), y[:, 1:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_! (generic function with 5 methods)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_!(opt, model, grads::Nothing) = model\n",
    "\n",
    "function update_!(opt::Optimise.Descent, arr::AbstractSparseMatrix, d_arr::AbstractSparseMatrix)\n",
    "    #print(\"spr_update \")\n",
    "    val_ptr = 1\n",
    "    col_val = 1\n",
    "    for (rows_begin, rows_end) in (zip(arr.colptr[1:end-1], arr.colptr[2:end]))\n",
    "        for row_ptr in rows_begin:(rows_end - 1)\n",
    "            row_val = arr.rowval[row_ptr]\n",
    "            arr.nzval[val_ptr] -= d_arr[row_val, col_val] * opt.eta\n",
    "            val_ptr += 1\n",
    "        end\n",
    "        col_val += 1\n",
    "    end\n",
    "    return arr\n",
    "end\n",
    "\n",
    "function update_!(opt, arr::AbstractArray, d_arr::AbstractArray)\n",
    "    #print(\"abs_arr_update \")\n",
    "    Optimise.apply!(opt, arr, d_arr)\n",
    "    arr .-= d_arr\n",
    "    return arr\n",
    "end\n",
    "\n",
    "function update_!(opt, model::Chain, grads) \n",
    "    for (layer, d_layer) in zip(model.layers, grads.layers)\n",
    "        d_layer = getfield(d_layer, 1)\n",
    "        @assert nfields(layer) == nfields(d_layer)\n",
    "        for field_index in 1:nfields(layer)\n",
    "            field = getfield(layer, field_index)\n",
    "            d_field = getfield(d_layer, field_index)\n",
    "            update_!(opt, field, d_field)\n",
    "        end\n",
    "    end\n",
    "#     #print(\"down \")\n",
    "#     @assert nfields(model) == nfields(grads)\n",
    "#             [\"nfields(model) $(nfields(model)) ≠ nfields(grads) $(nfields(grads))\"]\n",
    "#     for field_idx in 1:nfields(model)\n",
    "#         field = getfield(model, field_idx)\n",
    "#         d_field = getfield(grads, field_idx)\n",
    "#         update_!(opt, field, d_field)\n",
    "#     end\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augment! (generic function with 2 methods)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment!(x, y) = nothing\n",
    "\n",
    "function augment!(layer::SprAffine, frac::AbstractFloat)\n",
    "    # redraw fraction of the layer's Weights\n",
    "    I, J, V = findnz(layer.W)\n",
    "    #println(length(V))\n",
    "    len_augmented = floor(Int, frac * length(V))\n",
    "    len_preserved = length(V) - len_augmented\n",
    "    #println(len_augmented, \" \", len_preserved)\n",
    "    elems = Set(zip(I, J))\n",
    "    indices = sortperm(abs.(V), rev=true)[1:len_preserved]\n",
    "    I = I[indices]\n",
    "    J = J[indices]\n",
    "    V = V[indices]\n",
    "    I_ = similar(I, len_augmented)\n",
    "    J_ = similar(J, len_augmented)\n",
    "    V_ = similar(V, len_augmented)\n",
    "    index = 1\n",
    "    while index <= len_augmented\n",
    "        i = sample(1:size(layer.W, 1))\n",
    "        j = sample(1:size(layer.W, 2))\n",
    "        if (i,j) in elems\n",
    "            continue\n",
    "        end\n",
    "        push!(elems, (i, j))\n",
    "        I_[index] = i\n",
    "        J_[index] = j\n",
    "        V_[index] = randn()\n",
    "        index += 1\n",
    "    end\n",
    "    append!(I, I_)\n",
    "    append!(J, J_)\n",
    "    #println(length(V))\n",
    "    append!(V, V_)\n",
    "#     for index in 1:length(layer.W.nzval)\n",
    "#         layer.W.nzval[index] = 0.\n",
    "#     end\n",
    "#     droptol!(layer.W, Inf, trim=true)\n",
    "    layer.W = sparse(I, J, V, size(layer.W)...)\n",
    "    #println(length(V))\n",
    "    #println(length(layer.W.nzval))\n",
    "    #println(\" ---\")\n",
    "    return layer\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 < 3 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 4\n",
       " 7"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(1:3:10-3+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_augmenting! (generic function with 2 methods)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_augmenting!(opt, loss, model, (X, y), (X_val, y_val), batch_size, num_epochs,\n",
    "                           augmentation_period, augmentation_fraction)\n",
    "    X_val_sp = sparse(X_val)\n",
    "    for epoch in 1:num_epochs\n",
    "        println(\"Epoch: $epoch\")\n",
    "        perm = shuffle(1:size(X, 2))\n",
    "        X_sp = sparse(X[:, perm])\n",
    "        y_ = y[:, perm]\n",
    "        batch_indices = 1:batch_size:(size(X, 2) - batch_size + 1)\n",
    "        for (index, batch_index) in enumerate(batch_indices)\n",
    "            #print(\"Batch $index/$(length(batch_indices)) \")\n",
    "            loss_local, back = pullback(model) do model\n",
    "                loss(model,\n",
    "                     X_sp[:, 1:batch_size],\n",
    "                     y_[:, 1:batch_size])\n",
    "            end;\n",
    "            #print(round(loss_local, digits=4), \" \")\n",
    "            grads = back(1)[1];\n",
    "            #print(\"g \")\n",
    "            update_!(opt, model, grads)\n",
    "            acc = accuracy(model, X_val_sp, y_val)\n",
    "            print(round(acc, digits=4), \" \")\n",
    "            #print(\"u \")\n",
    "            #println(length(model[1].W.nzval) / length(model[1].W), \" \")\n",
    "            is_very_last_batch = (epoch == num_epochs) && (batch_index > size(X, 2) - 2batch_size)\n",
    "            if (index % augmentation_period == 0) && !is_very_last_batch\n",
    "                for layer in model.layers\n",
    "                    augment!(layer, augmentation_fraction)\n",
    "                end\n",
    "                print(\"\\n\")\n",
    "                #println(\"Augmented $augmentation_fraction of weights.\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "0.1312 0.1418 0.1481 0.1502 0.1532 0.1574 \n",
      "0.1714 0.1783 0.1835 0.1879 0.1933 0.1978 \n",
      "0.1983 0.2088 0.2168 0.2227 0.2283 0.233 \n",
      "0.2557 0.2581 0.2613 0.2647 0.2676 0.269 \n",
      "0.2797 0.2822 0.2848 0.2879 0.2911 0.2933 \n",
      "0.2788 0.2939 0.303 0.3088 0.3124 0.3172 \n",
      "0.3092 0.3167 0.3231 0.3271 0.332 0.3342 \n",
      "0.3196 0.3245 0.3278 0.3306 0.3334 0.3361 \n",
      "0.3108 0.3182 0.324 0.3271 0.3308 0.335 \n",
      "0.3325 0.3368 0.3405 0.345 0.3491 0.3522 \n",
      "0.3228 0.347 0.3627 0.368 0.3723 0.3773 \n",
      "0.3615 0.3702 0.376 0.3798 0.381 0.3832 \n",
      "0.3448 0.3518 0.3574 0.3643 0.3696 0.3736 \n",
      "0.3613 0.3672 0.3739 0.3782 0.3832 0.387 \n",
      "0.3853 0.3986 0.4032 0.4062 0.4065 0.4053 \n",
      "0.3974 0.4038 0.4088 0.4102 0.4134 0.4147 \n",
      "0.416 0.4186 0.4207 0.4233 0.426 0.4282 \n",
      "0.4126 0.4222 0.4264 0.4279 0.4309 0.4345 \n",
      "0.4358 0.4433 0.4488 0.4532 0.4553 0.4563 \n",
      "0.4439 0.4461 0.4495 0.4513 0.4532 0.4544 \n",
      "0.4983 0.5025 0.5044 0.5053 0.5064 0.5079 \n",
      "0.4703 0.4781 0.484 0.4897 0.4926 0.4942 \n",
      "0.4523 0.4592 0.4635 0.4667 0.4691 0.4707 \n",
      "0.433 0.4394 0.4421 0.4473 0.4497 0.451 \n",
      "0.4301 0.437 0.4428 0.4468 0.4492 0.4515 \n",
      "0.4678 0.4689 0.4705 0.4708 0.4722 0.4732 \n",
      "0.3994 0.4132 0.419 0.4233 0.4248 0.4268 \n",
      "0.4366 0.4442 0.4462 0.4472 0.4488 0.4506 \n",
      "0.3941 0.4048 0.4151 0.4227 0.4289 0.4342 \n",
      "0.4194 0.4242 0.428 0.4293 0.4305 0.433 \n",
      "0.4422 0.4443 0.4448 0.4456 0.4467 0.4486 \n",
      "0.3869 0.4036 0.411 0.4163 0.4207 0.4249 \n",
      "0.3948 0.4049 0.4106 0.4146 0.4186 0.422 \n",
      "0.414 "
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] (::Zygote.var\"#995#997\"{SparseMatrixCSC{Float32,Int64},Tuple{Colon,UnitRange{Int64}}})(::SparseMatrixCSC{Float32,Int64}) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/lib/array.jl:45",
      " [2] #2634#back at /home/olszewskip/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:49 [inlined]",
      " [3] #41 at ./In[172]:13 [inlined]",
      " [4] (::Zygote.var\"#28#29\"{typeof(∂(λ))})(::Int64) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/compiler/interface.jl:38",
      " [5] train_augmenting!(::Flux.Optimise.Descent, ::typeof(loss), ::Chain{Tuple{SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)},SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)}}}, ::Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}, ::Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}, ::Int64, ::Int64, ::Int64, ::Float64) at ./In[172]:18",
      " [6] top-level scope at In[174]:2"
     ]
    }
   ],
   "source": [
    "model = get_model(size(X, 1), 100, size(y, 1), 0.1)\n",
    "train_augmenting!(Optimise.Descent(0.1), loss, model, (X, y), (X_val, y_val),\n",
    "                  64, 1, 6, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "0.1572 0.1625 0.1689 0.1762 0.18 0.1831 0.1843 0.1878 0.1905 0.1938 0.1971 0.2008 0.2052 0.2088 0.2135 0.2158 \n",
      "0.1507 0.1572 0.164 0.1698 0.1743 0.1794 0.1835 0.1883 0.1925 0.1964 0.2006 0.2042 0.2078 0.2106 0.2133 0.2178 \n",
      "0.2382 0.2448 0.2452 0.2502 0.2525 0.2568 0.2615 0.2672 0.2737 0.2792 0.2855 0.292 0.2966 0.3006 0.3056 0.3098 \n",
      "0.2362 0.2418 0.2439 0.2507 0.2576 0.2638 0.2713 0.2782 0.2844 0.2917 0.2967 0.301 0.3053 0.3098 0.3136 0.3159 \n",
      "0.2099 0.221 0.2312 0.2418 0.2512 0.2583 0.2638 0.2696 0.2751 0.2777 0.281 0.2852 0.2889 0.2902 0.2921 0.2949 \n",
      "0.2578 0.2673 0.2733 0.2805 0.2864 0.2945 0.3026 0.3104 0.3167 0.323 0.3282 0.3312 0.3362 0.3398 0.344 0.3452 \n",
      "0.2419 0.2656 0.2853 0.2977 0.3051 0.3093 0.3132 0.3177 0.3219 0.3268 0.3312 0.3356 0.3392 0.3442 0.3481 0.3509 \n",
      "0.2558 0.2774 0.2995 0.3192 0.3264 0.3355 0.3398 0.3445 0.3485 0.3502 0.3529 0.3548 0.3562 0.3581 0.3597 0.3621 \n",
      "0.1605 0.1744 0.1862 0.1984 0.2089 0.2185 0.2252 0.2314 0.2358 0.2408 0.2456 0.2498 0.2536 0.2568 0.2602 0.2627 \n",
      "0.2448 0.2586 0.2679 0.2778 0.2852 0.2916 0.2964 0.3024 0.3071 0.3112 0.3163 0.3202 0.3248 0.3277 0.329 0.3308 \n",
      "0.3114 0.327 0.3397 0.3494 0.358 0.3644 0.3694 0.3723 0.3748 0.3781 0.3798 0.3824 0.3834 0.3852 0.3856 0.3875 \n",
      "0.2908 0.3014 0.3092 0.3174 0.3242 0.3307 0.3353 0.341 0.3448 0.3476 0.3508 0.3545 0.358 0.3612 0.3643 0.3677 \n",
      "0.3102 0.3247 0.3348 0.3429 0.3506 0.3568 0.3627 0.365 0.3678 0.3697 0.3716 0.3742 0.3756 0.3769 0.3782 0.3787 \n",
      "0.3599 0.3653 0.3711 0.3775 0.3829 0.3903 0.3946 0.3984 0.4027 0.4061 0.4075 0.4082 0.4096 0.4117 0.4128 0.4137 \n",
      "0.3122 0.3177 0.3232 0.3265 0.329 0.3316 0.3342 0.3373 0.3399 0.3422 0.3448 0.3472 0.3492 0.3509 0.3521 0.3524 \n",
      "0.2803 0.2927 0.3052 0.3141 0.322 0.3285 0.3318 0.335 0.3377 0.3402 0.343 0.3462 0.3492 0.3512 0.3531 0.3546 \n",
      "0.3412 0.3455 0.3492 0.3532 0.3537 0.355 0.3571 0.3577 0.3599 0.3607 0.3612 0.3631 0.3636 0.3648 0.3652 0.3658 \n",
      "0.2966 0.3037 0.3094 0.3151 0.3198 0.3262 0.3302 0.3348 0.3373 0.3398 0.3424 0.3447 0.3469 0.3481 0.3495 0.3507 \n",
      "0.2808 0.2912 0.301 0.3094 0.3171 0.3223 0.3262 0.3317 0.3345 0.3348 0.3365 0.3372 0.3375 0.3396 0.3405 0.3417 \n",
      "0.3804 0.3884 0.3952 0.3992 0.4024 0.4035 0.4033 0.4033 0.404 0.4052 0.4068 0.4073 0.4085 0.4093 0.4095 0.4108 \n",
      "0.2935 0.3048 0.3139 0.3187 0.3216 0.3246 0.3265 0.3291 0.332 0.3342 0.3348 0.336 0.3377 0.3392 0.3408 0.3426 \n",
      "0.2736 0.2855 0.2938 0.303 0.3095 0.3132 0.3162 0.3182 0.3198 0.3227 0.3239 0.3252 0.3269 0.328 0.33 0.3318 \n",
      "0.3383 0.3436 0.3511 0.3526 0.3529 0.3535 0.3538 0.3554 0.3579 0.3592 0.3602 0.361 0.3618 0.3629 0.3642 0.3653 \n",
      "0.3204 0.3219 0.3245 0.3254 0.3268 0.3282 0.3288 0.329 0.3298 0.3302 0.3311 0.3322 0.3338 0.3346 0.337 0.3378 \n",
      "0.2852 0.3093 0.3226 0.3292 0.3352 0.3398 0.3422 0.3439 0.346 0.3477 0.3496 0.3514 0.3522 0.3534 0.3538 0.3546 \n",
      "0.3619 0.3659 0.3701 0.3727 0.3744 0.377 0.3787 0.3802 0.383 0.3844 0.3862 0.3872 0.3888 0.3903 0.3918 0.3909 \n",
      "0.3597 0.3656 0.3709 0.374 0.3772 0.3792 0.3802 0.3809 0.3812 0.3822 0.3839 0.3854 0.3861 0.3873 0.3882 0.3886 \n",
      "0.3831 0.3943 0.4013 0.4078 0.4127 0.4173 0.4202 0.4249 0.4274 0.4287 0.4309 0.4333 0.4352 0.4357 0.4365 0.4365 \n",
      "0.3423 0.3564 0.3666 0.3747 0.3822 0.3862 0.391 0.3948 0.3978 0.3999 0.4025 0.4035 0.4052 0.4063 0.4068 0.4073 \n",
      "0.4191 0.4304 0.4409 0.4436 0.4468 0.4489 0.4512 0.4512 0.4531 0.4539 0.4547 0.4546 0.4546 0.4552 0.4553 0.4557 \n",
      "0.4153 0.4198 0.421 0.4228 0.4262 0.4284 0.4298 0.4314 0.4318 0.4334 0.4348 0.4352 0.4382 0.4388 0.439 0.4388 \n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] (::Zygote.var\"#995#997\"{SparseMatrixCSC{Float32,Int64},Tuple{Colon,UnitRange{Int64}}})(::SparseMatrixCSC{Float32,Int64}) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/lib/array.jl:45",
      " [2] #2634#back at /home/olszewskip/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:49 [inlined]",
      " [3] #41 at ./In[172]:13 [inlined]",
      " [4] (::Zygote.var\"#28#29\"{typeof(∂(λ))})(::Int64) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/compiler/interface.jl:38",
      " [5] train_augmenting!(::Flux.Optimise.Descent, ::typeof(loss), ::Chain{Tuple{SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)},SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)}}}, ::Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}, ::Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}, ::Int64, ::Int64, ::Int64, ::Float64) at ./In[172]:18",
      " [6] top-level scope at In[176]:2"
     ]
    }
   ],
   "source": [
    "model = get_model(size(X, 1), 100, size(y, 1), 0.1)\n",
    "train_augmenting!(Optimise.Descent(0.1), loss, model, (X, y), (X_val, y_val),\n",
    "                  64, 1, 16, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmenting!(Optimise.Descent(0.2), loss, model, (X, y), (X_val, y_val),\n",
    "                  64, 1, 5, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, sparse(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 Array{Float32,2}:\n",
       " -15.2978    39.3126     0.471826  …   11.5914     27.8094    16.3412  \n",
       " -14.4236   -31.6884   -19.7033       -24.9329    -18.037    -15.8129  \n",
       "   1.94016  -64.7316     8.30274      -31.5712    -10.1424   -36.3982  \n",
       "  21.5777    21.9106    12.6699       -16.7958      9.84951    0.533863\n",
       " -49.4807   -50.8089   -13.4105       -28.6316    -32.741    -12.1242  \n",
       "  11.3429     1.226     -2.5209    …    9.23097    29.3412    -6.88847 \n",
       " -12.4105   -22.5244    20.2417        -0.273212    5.67532    7.27039 \n",
       "  -2.42519   28.6859    -4.85765       -6.10574     7.92254   29.8143  \n",
       "   3.65144   -6.33468    8.74955       15.3897    -11.0637    -2.80236 \n",
       " -14.0099     7.8312     0.470142      15.9757     11.3657    12.9205  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array(model(sparse(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       "  6\n",
       "  1\n",
       "  5\n",
       "  2\n",
       " 10\n",
       "  3\n",
       "  2\n",
       "  4\n",
       "  2\n",
       "  5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecold(y[:, 1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/468 Loss: 12.903942\n",
      "Batch 2/468 Loss: 7.998606\n",
      "Batch 3/468 Loss: 5.978869\n",
      "Batch 4/468 Loss: 4.7153387\n",
      "Batch 5/468 Loss: 3.8186448\n",
      "Batch 6/468 Loss: 3.1671693\n",
      "Batch 7/468 Loss: 2.6950784\n",
      "Batch 8/468 Loss: 2.348345\n",
      "Batch 9/468 Loss: 2.077857\n",
      "Batch 10/468 Loss: 1.8604236\n",
      "Augmented 0.3 of weights.\n",
      "Batch 11/468 Loss: 6.780545\n",
      "Batch 12/468 Loss: 4.6947923\n",
      "Batch 13/468 Loss: 3.576496\n",
      "Batch 14/468 Loss: 3.0275183\n",
      "Batch 15/468 Loss: 2.3009427\n",
      "Batch 16/468 Loss: 1.9193074\n",
      "Batch 17/468 Loss: 1.6593554\n",
      "Batch 18/468 Loss: 1.4660087\n",
      "Batch 19/468 Loss: 1.3267179\n",
      "Batch 20/468 Loss: 1.2275671\n",
      "Augmented 0.3 of weights.\n",
      "Batch 21/468 Loss: 6.5453057\n",
      "Batch 22/468 Loss: 4.088305\n",
      "Batch 23/468 Loss: 2.9599335\n",
      "Batch 24/468 Loss: 1.8741505\n",
      "Batch 25/468 Loss: 1.1792691\n",
      "Batch 26/468 Loss: 0.8042897\n",
      "Batch 27/468 Loss: 0.651187\n",
      "Batch 28/468 Loss: 0.50910723\n",
      "Batch 29/468 Loss: 0.408691\n",
      "Batch 30/468 Loss: 0.34578425\n",
      "Augmented 0.3 of weights.\n",
      "Batch 31/468 Loss: 8.25316\n",
      "Batch 32/468 Loss: 3.3610651\n",
      "Batch 33/468 Loss: 1.8641839\n",
      "Batch 34/468 Loss: 1.6502843\n",
      "Batch 35/468 Loss: 1.7615561\n",
      "Batch 36/468 Loss: 0.5374702\n",
      "Batch 37/468 Loss: 0.30581087\n",
      "Batch 38/468 Loss: 0.19012406\n",
      "Batch 39/468 Loss: 0.11263185\n",
      "Batch 40/468 Loss: 0.08237183\n",
      "Augmented 0.3 of weights.\n",
      "Batch 41/468 Loss: 10.097649\n",
      "Batch 42/468 Loss: NaN\n",
      "Batch 43/468 Loss: NaN\n",
      "Batch 44/468 Loss: NaN\n",
      "Batch 45/468 Loss: NaN\n",
      "Batch 46/468 Loss: NaN\n",
      "Batch 47/468 Loss: NaN\n",
      "Batch 48/468 Loss: NaN\n",
      "Batch 49/468 Loss: NaN\n",
      "Batch 50/468 Loss: NaN\n",
      "Augmented 0.3 of weights.\n",
      "Batch 51/468 Loss: NaN\n",
      "Batch 52/468 Loss: NaN\n",
      "Batch 53/468 Loss: NaN\n",
      "Batch 54/468 Loss: NaN\n",
      "Batch 55/468 Loss: NaN\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] (::Zygote.var\"#995#997\"{SparseMatrixCSC{Float32,Int64},Tuple{Colon,UnitRange{Int64}}})(::SparseMatrixCSC{Float32,Int64}) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/lib/array.jl:45",
      " [2] (::Zygote.var\"#2634#back#991\"{Zygote.var\"#995#997\"{SparseMatrixCSC{Float32,Int64},Tuple{Colon,UnitRange{Int64}}}})(::SparseMatrixCSC{Float32,Int64}) at /home/olszewskip/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:49",
      " [3] #25 at ./In[43]:11 [inlined]",
      " [4] (::typeof(∂(λ)))(::Int64) at /home/olszewskip/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [5] #28 at /home/olszewskip/.julia/packages/Zygote/oMScO/src/compiler/interface.jl:38 [inlined]",
      " [6] train_augmenting!(::Flux.Optimise.Descent, ::typeof(loss), ::Chain{Tuple{SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)},SprAffine{SparseMatrixCSC{Float32,Int64},Array{Float32,1},typeof(identity)},typeof(softmax)}}, ::Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}, ::Int64, ::Int64, ::Int64, ::Float64) at ./In[43]:16",
      " [7] top-level scope at In[44]:2"
     ]
    }
   ],
   "source": [
    "# model = get_model()\n",
    "# train_augmenting!(Optimise.Descent(0.3), loss, model, (X, y), 128, 10, 10, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
